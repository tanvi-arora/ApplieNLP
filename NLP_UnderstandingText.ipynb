{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.17134-SP0\n",
      "Python 3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]\n",
      "nltk 3.4.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.platform())\n",
    "\n",
    "import sys\n",
    "print(\"Python\",sys.version)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "print(\"nltk\",nltk.__version__)\n",
    "\n",
    "## for percentage string match\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "## for Regex Tokenizer\n",
    "import re\n",
    "\n",
    "## for Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "## for Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between 2 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_editdistance(str1,str2):\n",
    "    return nltk.edit_distance(str1,str2,1,False)\n",
    "\n",
    "def print_editdistance(text1,text2):\n",
    "    print(\"Edit distance between \",text1,\" and \",text2,\" is \",get_editdistance(text1,text2))\n",
    "    print(\"Edit distance between \",text1,\" and \",text2,\" is \",get_editdistance(text2,text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_name='Tanvi'\n",
    "nick_name=['Tanu','Frazi','Mitthi','Bhanu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance between  Tanvi  and  Tanu  is  2\n",
      "Edit distance between  Tanvi  and  Tanu  is  2\n",
      "===================Next Name====================\n",
      "Edit distance between  Tanvi  and  Frazi  is  4\n",
      "Edit distance between  Tanvi  and  Frazi  is  4\n",
      "===================Next Name====================\n",
      "Edit distance between  Tanvi  and  Mitthi  is  5\n",
      "Edit distance between  Tanvi  and  Mitthi  is  5\n",
      "===================Next Name====================\n",
      "Edit distance between  Tanvi  and  Bhanu  is  4\n",
      "Edit distance between  Tanvi  and  Bhanu  is  4\n",
      "===================Next Name====================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for nn in nick_name:\n",
    "    print_editdistance(given_name,nn)\n",
    "    print(\"===================Next Name====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage String match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stringmatch(str1,str2):\n",
    "    m=SequenceMatcher(None,str1,str2)\n",
    "    print(\"Percentage string match between \",str1,\" and \",str2,\" is \",m.ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage string match between  Tanvi  and  Tanu  is  66.66666666666666\n",
      "===================Next Name====================\n",
      "Percentage string match between  Tanvi  and  Frazi  is  40.0\n",
      "===================Next Name====================\n",
      "Percentage string match between  Tanvi  and  Mitthi  is  18.181818181818183\n",
      "===================Next Name====================\n",
      "Percentage string match between  Tanvi  and  Bhanu  is  40.0\n",
      "===================Next Name====================\n"
     ]
    }
   ],
   "source": [
    "for nn in nick_name:\n",
    "    get_stringmatch(given_name,nn)\n",
    "    print(\"===================Next Name====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_text=\"THis is a sample text, for you'll. Given Jasmine is coming. I will not resume until then\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordtokens(text):\n",
    "    # word tokenization\n",
    "    default_wt = nltk.word_tokenize\n",
    "    words=default_wt(text)\n",
    "    only_words=[w for w in words if w.isalpha()]\n",
    "    return only_words\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stopword_list=nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens=[token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_nostpwrds=remove_stopwords(get_wordtokens(book_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_porterstemmer(words):\n",
    "    ps=PorterStemmer()\n",
    "    stemmed_words=[ps.stem(w) for w in words]\n",
    "    return stemmed_words\n",
    "\n",
    "def apply_lancasterstemmer(words):\n",
    "    ls=LancasterStemmer()\n",
    "    stemmed_words=[ls.stem(w) for w in words]\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PorterStemmer to word list cleaned off stopwords\n",
      "['thi', 'sampl', 'text', 'given', 'jasmin', 'come', 'I', 'resum']\n",
      "\n",
      "Applying LancasterStemmer to word list cleaned off stopwords\n",
      "['thi', 'sampl', 'text', 'giv', 'jasmin', 'com', 'i', 'resum']\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying PorterStemmer to word list cleaned off stopwords\")\n",
    "ps_stemmed_words=apply_porterstemmer(words_nostpwrds)\n",
    "print(ps_stemmed_words)\n",
    "print()\n",
    "print(\"Applying LancasterStemmer to word list cleaned off stopwords\")\n",
    "ls_stemmed_words=apply_lancasterstemmer(words_nostpwrds)\n",
    "print(ls_stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lemmas(words):\n",
    "    lemmas=[]\n",
    "    wnl=WordNetLemmatizer()\n",
    "    lemmas_n=[wnl.lemmatize(w.lower(),'n') for w in words if wnl.lemmatize(w.lower(),'n')!= w.lower() ]\n",
    "    lemmas_v=[wnl.lemmatize(w.lower(),'v') for w in words if wnl.lemmatize(w.lower(),'v')!= w.lower() ]\n",
    "    lemmas_a=[wnl.lemmatize(w.lower(),'a') for w in words if wnl.lemmatize(w.lower(),'a')!= w.lower() ]\n",
    "    lemmas.extend(lemmas_n)\n",
    "    lemmas.extend(lemmas_v)\n",
    "    lemmas.extend(lemmas_a)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give\n"
     ]
    }
   ],
   "source": [
    "wnl=WordNetLemmatizer()\n",
    "print(wnl.lemmatize('given','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas=find_lemmas(words_nostpwrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_morphologicalroots(lemmas,stemwords):\n",
    "    return [sw for sw in stemwords if sw in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphological roots in ps stemmed words :- \n",
      "['come']\n",
      "\n",
      "==============================\n",
      "\n",
      "morphological roots in ls stemmed words:- \n",
      "No Morphological roots in ls stemmer\n"
     ]
    }
   ],
   "source": [
    "print(\"morphological roots in ps stemmed words :- \")\n",
    "if find_morphologicalroots(lemmas,ps_stemmed_words):\n",
    "    print(find_morphologicalroots(lemmas,ps_stemmed_words))\n",
    "else:\n",
    "    print(\"No Morphological roots in ps stemmer\")\n",
    "\n",
    "print()\n",
    "print(\"==============================\")\n",
    "print()\n",
    "\n",
    "print(\"morphological roots in ls stemmed words:- \")\n",
    "if find_morphologicalroots(lemmas,ls_stemmed_words):\n",
    "    print(find_morphologicalroots(lemmas,ls_stemmed_words))\n",
    "else:\n",
    "    print(\"No Morphological roots in ls stemmer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
